
# Fake News Detection Using Semantic Classification (Word2Vec)

## ğŸ“Œ Problem Statement
The spread of fake news in digital media is a serious challenge, contributing to misinformation and public confusion. This project focuses on building a supervised classification system to distinguish fake news from true news articles using semantic features derived from Word2Vec.

## ğŸ“Š Dataset Description
Two datasets were provided:
- **True News** (`True.csv`): 21,417 articles with columns: `title`, `text`, `date`
- **Fake News** (`Fake.csv`): 23,502 articles (with some null values) with the same columns

Each article contains:
- `title`: The article headline
- `text`: The main body of the article
- `date`: Date of publication

A new column `news_label` was added:
- `1` for True news
- `0` for Fake news

## ğŸ”„ Data Preparation
- Missing values in `title`, `text`, or `date` were removed
- Irrelevant columns were dropped after merging the data
- Merged data was shuffled and reset for downstream tasks

## âœï¸ Text Preprocessing
- Lowercasing, punctuation removal, and stopword filtering
- Tokenization and POS tagging
- Lemmatization (retaining nouns, verbs, adjectives, and adverbs)

## ğŸ“‚ Train-Validation Split
- Dataset was split into 70% training and 30% validation using `train_test_split` with a fixed `random_state`

## ğŸ“ˆ Exploratory Data Analysis (EDA)
- Distribution of character lengths before and after lemmatization visualized
- Top 40 most frequent words identified for both True and Fake news
- Top unigrams, bigrams, and trigrams extracted using `CountVectorizer`

## ğŸ§  Feature Engineering: Word2Vec
- `gensim.models.Word2Vec` trained on tokenized lemmatized text
- News vectors generated by averaging word embeddings

## ğŸ¤– Model Training & Evaluation
Three models were trained and evaluated:

| Model              | Accuracy | Precision | Recall | F1 Score |
|-------------------|----------|-----------|--------|----------|
| LogisticRegression| TBD      | TBD       | TBD    | TBD      |
| DecisionTree      | TBD      | TBD       | TBD    | TBD      |
| RandomForest      | TBD      | TBD       | TBD    | TBD      |

*(TBDs will be filled once model evaluation is complete)*

## ğŸ Conclusion
- Semantic classification using Word2Vec effectively captures thematic similarities in fake and true news.
- The model with the best balance of F1 Score and Precision will be selected for deployment.
- This approach highlights the importance of combining NLP techniques with traditional ML models to mitigate misinformation.

## ğŸ“Œ Assumptions
- Only articles with complete `title`, `text`, and `date` fields were used
- Only English stopwords and POS tags were considered
- Word2Vec trained on assignment-specific corpus rather than a pre-trained model for contextual accuracy


---

## ğŸ‘¨â€ğŸ’» Authors
- Sravana Sanka
- Shriyan